{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pruning techniques in keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we are going to see :\n",
    "    1. How to use pruning in Tensorflow Keras\n",
    "    2. How to convert the model to tensorflow lite\n",
    "    3. Inference the model\n",
    "    4. Extract pruned model weights\n",
    "    5. Pruning + Quantisation\n",
    "    6. Comparision of models with Original Model + Pruned Model + Quantised Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------------------\n",
    "Here we are going to prune already trained model in keras.\n",
    "Let us first import the pre-trained model here...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessery packages\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import pickle\n",
    "import tensorflow_model_optimization as tfmot\n",
    "import time\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\ghodam2\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 48, 48, 1)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 48, 48, 32)   832         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 48, 48, 32)   0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 24, 24, 32)   0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 24, 24, 32)   25632       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 24, 24, 32)   0           conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 12, 12, 32)   0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 12, 12, 64)   51264       max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 12, 12, 64)   0           conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 6, 6, 64)     0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 6, 6, 128)    204928      max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 6, 6, 128)    0           conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2D)  (None, 3, 3, 64)     0           max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)  (None, 3, 3, 32)     0           max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 3, 3, 128)    0           activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)             (None, 576)          0           max_pooling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 288)          0           max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 1152)         0           max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 864)          0           flatten_3[0][0]                  \n",
      "                                                                 flatten_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 2016)         0           flatten_1[0][0]                  \n",
      "                                                                 concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 256)          516352      concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 128)          32896       dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 6)            774         dense_2[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 832,678\n",
      "Trainable params: 832,678\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Load model\n",
    "model = tf.keras.models.load_model(\"TrafficSignalClassifier_v4_2.h5\")\n",
    "\n",
    "# check model architecture\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(test_data_path):\n",
    "    class_ids = ['background', 'red', 'red-yellow', 'green', 'yellow', 'off']\n",
    "    IMG_SIZE = 48\n",
    "    test_image = []\n",
    "    test_label = []\n",
    "    for class_id in class_ids:\n",
    "        testpath = os.path.join(test_data_path,class_id)\n",
    "        class_num = class_ids.index(class_id)\n",
    "        for img in os.listdir(testpath):\n",
    "            try:\n",
    "                test_img_array = cv2.imread(os.path.join(testpath, img), cv2.IMREAD_GRAYSCALE)\n",
    "                # preprocessing\n",
    "                test_img_array = cv2.resize(test_img_array, (IMG_SIZE, IMG_SIZE))\n",
    "                test_img_array = test_img_array.reshape(IMG_SIZE, IMG_SIZE, 1)\n",
    "                test_img_array = test_img_array/255\n",
    "                test_image.append(test_img_array)\n",
    "                test_label.append(class_num)\n",
    "            except Exception as e:\n",
    "                print(\"Error : Incorrect Path\")\n",
    "    test_image = np.array(test_image)\n",
    "    test_label = np.array(test_label)\n",
    "    return test_image, test_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000/2000 [==============================] - 2s 933us/sample - loss: 0.1999 - acc: 0.9645\n",
      "Baseline test accuracy: 0.9645\n"
     ]
    }
   ],
   "source": [
    "# Load Test Data\n",
    "test_data_path=\"C:\\\\Users\\\\ghodam2\\\\Desktop\\\\Pruning Technique\\\\test\"\n",
    "test_images, test_labels = load_data(test_data_path)\n",
    "\n",
    "# Check for Accuracy for orriginal Model\n",
    "_, original_model_accuracy = model.evaluate(test_images, test_labels)\n",
    "\n",
    "#Print Accuracy\n",
    "print('Baseline test accuracy:', original_model_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****************************************************************\n",
    "Load Training data for pruning the model. \n",
    "****************************************************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_in = open(\"X.pickle\", \"rb\")\n",
    "X = pickle.load(pickle_in)\n",
    "\n",
    "pickle_in = open(\"y.pickle\", \"rb\")\n",
    "y = pickle.load(pickle_in)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fine tuning model with the help of tensorflow optimization package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0x000002493604A9E8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0x000002493604A9E8>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0x000002493604A9E8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0x000002493604A9E8>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:From c:\\users\\ghodam2\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow_model_optimization\\python\\core\\sparsity\\keras\\pruning_wrapper.py:238: The name tf.debugging.assert_greater_equal is deprecated. Please use tf.compat.v1.debugging.assert_greater_equal instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\users\\ghodam2\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow_model_optimization\\python\\core\\sparsity\\keras\\pruning_schedule.py:240: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "WARNING:tensorflow:From c:\\users\\ghodam2\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow_model_optimization\\python\\core\\keras\\compat.py:25: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "WARNING:tensorflow:Entity <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0x000002494B861DA0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0x000002494B861DA0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0x000002494B861DA0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0x000002494B861DA0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0x000002494EE8FF98>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0x000002494EE8FF98>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0x000002494EE8FF98>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0x000002494EE8FF98>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0x000002494E5F05C0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0x000002494E5F05C0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0x000002494E5F05C0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0x000002494E5F05C0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0x000002494D396908>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0x000002494D396908>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0x000002494D396908>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0x000002494D396908>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0x000002494E91AE80>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0x000002494E91AE80>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0x000002494E91AE80>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0x000002494E91AE80>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0x000002494E76DD30>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0x000002494E76DD30>>: AttributeError: module 'gast' has no attribute 'Num'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Entity <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0x000002494E76DD30>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0x000002494E76DD30>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0x000002494E5D1CF8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0x000002494E5D1CF8>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0x000002494E5D1CF8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0x000002494E5D1CF8>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0x0000024953688470>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0x0000024953688470>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0x0000024953688470>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0x0000024953688470>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0x0000024953827F28>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0x0000024953827F28>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0x0000024953827F28>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0x0000024953827F28>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0x00000249535DDC18>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0x00000249535DDC18>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0x00000249535DDC18>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0x00000249535DDC18>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0x00000249535DD080>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0x00000249535DD080>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0x00000249535DD080>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0x00000249535DD080>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0x00000249537F5F60>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0x00000249537F5F60>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0x00000249537F5F60>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0x00000249537F5F60>>: AttributeError: module 'gast' has no attribute 'Num'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0x0000024953BB4FD0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0x0000024953BB4FD0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0x0000024953BB4FD0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0x0000024953BB4FD0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0x000002494E8816D8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0x000002494E8816D8>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0x000002494E8816D8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0x000002494E8816D8>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0x0000024953C91978>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0x0000024953C91978>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0x0000024953C91978>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0x0000024953C91978>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0x0000024953A16C18>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0x0000024953A16C18>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0x0000024953A16C18>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0x0000024953A16C18>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0x0000024953BEACC0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0x0000024953BEACC0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0x0000024953BEACC0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0x0000024953BEACC0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0x0000024953CDA358>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0x0000024953CDA358>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0x0000024953CDA358>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0x0000024953CDA358>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0x0000024953A50A20>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0x0000024953A50A20>>: AttributeError: module 'gast' has no attribute 'Num'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Entity <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0x0000024953A50A20>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0x0000024953A50A20>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0x00000249543282E8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0x00000249543282E8>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0x00000249543282E8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0x00000249543282E8>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0x0000024954117710>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0x0000024954117710>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0x0000024954117710>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method PruneLowMagnitude.call of <tensorflow_model_optimization.python.core.sparsity.keras.pruning_wrapper.PruneLowMagnitude object at 0x0000024954117710>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 48, 48, 1)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "prune_low_magnitude_conv2d_1 (P (None, 48, 48, 32)   1634        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "prune_low_magnitude_activation_ (None, 48, 48, 32)   1           prune_low_magnitude_conv2d_1[0][0\n",
      "__________________________________________________________________________________________________\n",
      "prune_low_magnitude_max_pooling (None, 24, 24, 32)   1           prune_low_magnitude_activation_1[\n",
      "__________________________________________________________________________________________________\n",
      "prune_low_magnitude_conv2d_2 (P (None, 24, 24, 32)   51234       prune_low_magnitude_max_pooling2d\n",
      "__________________________________________________________________________________________________\n",
      "prune_low_magnitude_activation_ (None, 24, 24, 32)   1           prune_low_magnitude_conv2d_2[0][0\n",
      "__________________________________________________________________________________________________\n",
      "prune_low_magnitude_max_pooling (None, 12, 12, 32)   1           prune_low_magnitude_activation_2[\n",
      "__________________________________________________________________________________________________\n",
      "prune_low_magnitude_conv2d_3 (P (None, 12, 12, 64)   102466      prune_low_magnitude_max_pooling2d\n",
      "__________________________________________________________________________________________________\n",
      "prune_low_magnitude_activation_ (None, 12, 12, 64)   1           prune_low_magnitude_conv2d_3[0][0\n",
      "__________________________________________________________________________________________________\n",
      "prune_low_magnitude_max_pooling (None, 6, 6, 64)     1           prune_low_magnitude_activation_3[\n",
      "__________________________________________________________________________________________________\n",
      "prune_low_magnitude_conv2d_4 (P (None, 6, 6, 128)    409730      prune_low_magnitude_max_pooling2d\n",
      "__________________________________________________________________________________________________\n",
      "prune_low_magnitude_activation_ (None, 6, 6, 128)    1           prune_low_magnitude_conv2d_4[0][0\n",
      "__________________________________________________________________________________________________\n",
      "prune_low_magnitude_max_pooling (None, 3, 3, 64)     1           prune_low_magnitude_max_pooling2d\n",
      "__________________________________________________________________________________________________\n",
      "prune_low_magnitude_max_pooling (None, 3, 3, 32)     1           prune_low_magnitude_max_pooling2d\n",
      "__________________________________________________________________________________________________\n",
      "prune_low_magnitude_max_pooling (None, 3, 3, 128)    1           prune_low_magnitude_activation_4[\n",
      "__________________________________________________________________________________________________\n",
      "prune_low_magnitude_flatten_3 ( (None, 576)          1           prune_low_magnitude_max_pooling2d\n",
      "__________________________________________________________________________________________________\n",
      "prune_low_magnitude_flatten_2 ( (None, 288)          1           prune_low_magnitude_max_pooling2d\n",
      "__________________________________________________________________________________________________\n",
      "prune_low_magnitude_flatten_1 ( (None, 1152)         1           prune_low_magnitude_max_pooling2d\n",
      "__________________________________________________________________________________________________\n",
      "prune_low_magnitude_concatenate (None, 864)          1           prune_low_magnitude_flatten_3[0][\n",
      "                                                                 prune_low_magnitude_flatten_2[0][\n",
      "__________________________________________________________________________________________________\n",
      "prune_low_magnitude_concatenate (None, 2016)         1           prune_low_magnitude_flatten_1[0][\n",
      "                                                                 prune_low_magnitude_concatenate_1\n",
      "__________________________________________________________________________________________________\n",
      "prune_low_magnitude_dense_1 (Pr (None, 256)          1032450     prune_low_magnitude_concatenate_2\n",
      "__________________________________________________________________________________________________\n",
      "prune_low_magnitude_dense_2 (Pr (None, 128)          65666       prune_low_magnitude_dense_1[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "prune_low_magnitude_dense_3 (Pr (None, 6)            1544        prune_low_magnitude_dense_2[0][0]\n",
      "==================================================================================================\n",
      "Total params: 1,664,739\n",
      "Trainable params: 832,678\n",
      "Non-trainable params: 832,061\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Compute end step to finish pruning after 2 epochs.\n",
    "batch_size = 128\n",
    "epochs = 2\n",
    "validation_split = 0.1 # 10% of training set will be used for validation set. \n",
    "\n",
    "num_images = X.shape[0] * (1 - validation_split)\n",
    "end_step = np.ceil(num_images / batch_size).astype(np.int32) * epochs\n",
    "\n",
    "# Define model for pruning.\n",
    "pruning_params = {\n",
    "      'pruning_schedule': tfmot.sparsity.keras.PolynomialDecay(initial_sparsity=0.50,\n",
    "                                                               final_sparsity=0.80,\n",
    "                                                               begin_step=0,\n",
    "                                                               end_step=end_step)\n",
    "}\n",
    "\n",
    "model_for_pruning = tfmot.sparsity.keras.prune_low_magnitude(model, **pruning_params)\n",
    "\n",
    "# `prune_low_magnitude` requires a recompile.\n",
    "model_for_pruning.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model_for_pruning.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 207516 samples, validate on 23058 samples\n",
      "Epoch 1/2\n",
      "207516/207516 [==============================] - 579s 3ms/sample - loss: 1.0593 - acc: 0.9854 - val_loss: 1.0612 - val_acc: 0.9818\n",
      "Epoch 2/2\n",
      "207516/207516 [==============================] - 572s 3ms/sample - loss: 1.0584 - acc: 0.9848 - val_loss: 1.0582 - val_acc: 0.9853\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 48, 48, 1)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "prune_low_magnitude_conv2d_1 (P (None, 48, 48, 32)   1634        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "prune_low_magnitude_activation_ (None, 48, 48, 32)   1           prune_low_magnitude_conv2d_1[0][0\n",
      "__________________________________________________________________________________________________\n",
      "prune_low_magnitude_max_pooling (None, 24, 24, 32)   1           prune_low_magnitude_activation_1[\n",
      "__________________________________________________________________________________________________\n",
      "prune_low_magnitude_conv2d_2 (P (None, 24, 24, 32)   51234       prune_low_magnitude_max_pooling2d\n",
      "__________________________________________________________________________________________________\n",
      "prune_low_magnitude_activation_ (None, 24, 24, 32)   1           prune_low_magnitude_conv2d_2[0][0\n",
      "__________________________________________________________________________________________________\n",
      "prune_low_magnitude_max_pooling (None, 12, 12, 32)   1           prune_low_magnitude_activation_2[\n",
      "__________________________________________________________________________________________________\n",
      "prune_low_magnitude_conv2d_3 (P (None, 12, 12, 64)   102466      prune_low_magnitude_max_pooling2d\n",
      "__________________________________________________________________________________________________\n",
      "prune_low_magnitude_activation_ (None, 12, 12, 64)   1           prune_low_magnitude_conv2d_3[0][0\n",
      "__________________________________________________________________________________________________\n",
      "prune_low_magnitude_max_pooling (None, 6, 6, 64)     1           prune_low_magnitude_activation_3[\n",
      "__________________________________________________________________________________________________\n",
      "prune_low_magnitude_conv2d_4 (P (None, 6, 6, 128)    409730      prune_low_magnitude_max_pooling2d\n",
      "__________________________________________________________________________________________________\n",
      "prune_low_magnitude_activation_ (None, 6, 6, 128)    1           prune_low_magnitude_conv2d_4[0][0\n",
      "__________________________________________________________________________________________________\n",
      "prune_low_magnitude_max_pooling (None, 3, 3, 64)     1           prune_low_magnitude_max_pooling2d\n",
      "__________________________________________________________________________________________________\n",
      "prune_low_magnitude_max_pooling (None, 3, 3, 32)     1           prune_low_magnitude_max_pooling2d\n",
      "__________________________________________________________________________________________________\n",
      "prune_low_magnitude_max_pooling (None, 3, 3, 128)    1           prune_low_magnitude_activation_4[\n",
      "__________________________________________________________________________________________________\n",
      "prune_low_magnitude_flatten_3 ( (None, 576)          1           prune_low_magnitude_max_pooling2d\n",
      "__________________________________________________________________________________________________\n",
      "prune_low_magnitude_flatten_2 ( (None, 288)          1           prune_low_magnitude_max_pooling2d\n",
      "__________________________________________________________________________________________________\n",
      "prune_low_magnitude_flatten_1 ( (None, 1152)         1           prune_low_magnitude_max_pooling2d\n",
      "__________________________________________________________________________________________________\n",
      "prune_low_magnitude_concatenate (None, 864)          1           prune_low_magnitude_flatten_3[0][\n",
      "                                                                 prune_low_magnitude_flatten_2[0][\n",
      "__________________________________________________________________________________________________\n",
      "prune_low_magnitude_concatenate (None, 2016)         1           prune_low_magnitude_flatten_1[0][\n",
      "                                                                 prune_low_magnitude_concatenate_1\n",
      "__________________________________________________________________________________________________\n",
      "prune_low_magnitude_dense_1 (Pr (None, 256)          1032450     prune_low_magnitude_concatenate_2\n",
      "__________________________________________________________________________________________________\n",
      "prune_low_magnitude_dense_2 (Pr (None, 128)          65666       prune_low_magnitude_dense_1[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "prune_low_magnitude_dense_3 (Pr (None, 6)            1544        prune_low_magnitude_dense_2[0][0]\n",
      "==================================================================================================\n",
      "Total params: 1,664,739\n",
      "Trainable params: 832,678\n",
      "Non-trainable params: 832,061\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "logdir = 'C:\\\\Users\\\\ghodam2\\\\Desktop\\\\Pruning Technique\\\\log'\n",
    "\n",
    "X = X/255\n",
    "callbacks = [\n",
    "  tfmot.sparsity.keras.UpdatePruningStep(),\n",
    "  tfmot.sparsity.keras.PruningSummaries(log_dir=logdir),\n",
    "]\n",
    "  \n",
    "model_for_pruning.fit(X, y,\n",
    "                  batch_size=batch_size, epochs=epochs, validation_split=validation_split,\n",
    "                  callbacks=callbacks)\n",
    "\n",
    "# Store pruned model with all pruning wrappers \n",
    "model_for_pruning.save(\"SaveModelAfterPruning.h5\")  \n",
    "\n",
    "model_for_pruning.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us compare the accuracy of both models\n",
    "------------------------------------------------------------------\n",
    "    1. Original model of keras\n",
    "    2. Model after using pruning on original keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original test accuracy: 0.9645\n",
      "Pruned test accuracy: 0.9605\n"
     ]
    }
   ],
   "source": [
    "_, model_for_pruning_accuracy = model_for_pruning.evaluate(\n",
    "   test_images, test_labels, verbose=0)\n",
    "\n",
    "print('Original test accuracy:', original_model_accuracy) \n",
    "print('Pruned test accuracy:', model_for_pruning_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Strip the model which was pruned earlier to see how much compression has been done after pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved pruned Keras model to: pruned_stripped_model.h5\n"
     ]
    }
   ],
   "source": [
    "# This will remove all wrappers from earlier prunned model and only keep original layers of model\n",
    "model_for_export = tfmot.sparsity.keras.strip_pruning(model_for_pruning)\n",
    "\n",
    "pruned_keras_file = 'pruned_stripped_model.h5'\n",
    "model_for_export.save(pruned_keras_file)\n",
    "\n",
    "print('Saved pruned Keras model to:', pruned_keras_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us see the weights distribution between original model vs pruned stripped model\n",
    "* Number of zeros and non zeros weights in model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_weights(model_name):\n",
    "    for i, w in enumerate(model_name.get_weights()):\n",
    "        print(\n",
    "            \"{} -- Total:{}, Zeros: {:.2f}%\".format(\n",
    "                model_name.weights[i].name, w.size, np.sum(w == 0) / w.size * 100\n",
    "            )\n",
    "        )\n",
    "        \n",
    "    print(\"<=============================================================================>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\ghodam2\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:97: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From c:\\users\\ghodam2\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "Weights Distibution for Original Model\n",
      "---------------------------------------\n",
      "conv2d_1_2/kernel:0 -- Total:800, Zeros: 0.00%\n",
      "conv2d_1_2/bias:0 -- Total:32, Zeros: 0.00%\n",
      "conv2d_2_2/kernel:0 -- Total:25600, Zeros: 0.00%\n",
      "conv2d_2_2/bias:0 -- Total:32, Zeros: 0.00%\n",
      "conv2d_3_2/kernel:0 -- Total:51200, Zeros: 0.00%\n",
      "conv2d_3_2/bias:0 -- Total:64, Zeros: 0.00%\n",
      "conv2d_4_2/kernel:0 -- Total:204800, Zeros: 0.00%\n",
      "conv2d_4_2/bias:0 -- Total:128, Zeros: 0.00%\n",
      "dense_1_2/kernel:0 -- Total:516096, Zeros: 0.00%\n",
      "dense_1_2/bias:0 -- Total:256, Zeros: 0.00%\n",
      "dense_2_2/kernel:0 -- Total:32768, Zeros: 0.00%\n",
      "dense_2_2/bias:0 -- Total:128, Zeros: 0.00%\n",
      "dense_3_2/kernel:0 -- Total:768, Zeros: 0.00%\n",
      "dense_3_2/bias:0 -- Total:6, Zeros: 0.00%\n",
      "<=============================================================================>\n",
      "Weights Distibution for Pruned Model\n",
      "---------------------------------------\n",
      "conv2d_1_3/kernel:0 -- Total:800, Zeros: 80.00%\n",
      "conv2d_1_3/bias:0 -- Total:32, Zeros: 0.00%\n",
      "conv2d_2_3/kernel:0 -- Total:25600, Zeros: 80.00%\n",
      "conv2d_2_3/bias:0 -- Total:32, Zeros: 0.00%\n",
      "conv2d_3_3/kernel:0 -- Total:51200, Zeros: 80.00%\n",
      "conv2d_3_3/bias:0 -- Total:64, Zeros: 0.00%\n",
      "conv2d_4_3/kernel:0 -- Total:204800, Zeros: 80.00%\n",
      "conv2d_4_3/bias:0 -- Total:128, Zeros: 0.00%\n",
      "dense_1_3/kernel:0 -- Total:516096, Zeros: 80.00%\n",
      "dense_1_3/bias:0 -- Total:256, Zeros: 0.00%\n",
      "dense_2_3/kernel:0 -- Total:32768, Zeros: 80.00%\n",
      "dense_2_3/bias:0 -- Total:128, Zeros: 0.00%\n",
      "dense_3_3/kernel:0 -- Total:768, Zeros: 79.95%\n",
      "dense_3_3/bias:0 -- Total:6, Zeros: 0.00%\n",
      "<=============================================================================>\n"
     ]
    }
   ],
   "source": [
    "# compare the original model + pruned and stripped model\n",
    "original_model = tf.keras.models.load_model('TrafficSignalClassifier_v4_2.h5')\n",
    "model_pruned_stripped = tf.keras.models.load_model('pruned_stripped_model.h5')\n",
    "\n",
    "print(\"Weights Distibution for Original Model\")\n",
    "print(\"---------------------------------------\")\n",
    "fetch_weights(original_model)\n",
    "\n",
    "print(\"Weights Distibution for Pruned Model\")\n",
    "print(\"---------------------------------------\")\n",
    "fetch_weights(model_pruned_stripped)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets check the weights from each model\n",
    "    1. Original Model\n",
    "    2. Pruned Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_weights(model_name, file_name):\n",
    "    weights_file = file_name  \n",
    "    with open(weights_file, 'w+') as f:\n",
    "        for i, w in enumerate(model_name.get_weights()):\n",
    "            f.write(\"\".join(\" \".join(map(str, x)) for x in model_name.weights[i].name))\n",
    "            f.write(\"\\n\")\n",
    "            f.write(\"\".join(\" \".join(map(str, w))))\n",
    "            f.write(\"\\n\")\n",
    "    print(weights_file)        \n",
    "    print(\"<=============================================================================>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original_model.weights\n",
      "<=============================================================================>\n",
      "WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "pruned_stripped_model.weights\n",
      "<=============================================================================>\n"
     ]
    }
   ],
   "source": [
    "# Load model\n",
    "original_model = tf.keras.models.load_model(\"TrafficSignalClassifier_v4_2.h5\")\n",
    "store_weights(original_model, 'original_model.weights')\n",
    "\n",
    "original_model = tf.keras.models.load_model(\"pruned_stripped_model.h5\")\n",
    "store_weights(original_model, 'pruned_stripped_model.weights')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 48\n",
    "\n",
    "class_ids = ['background', 'red', 'red-yellow', 'green', 'yellow', 'off']\n",
    "\n",
    "def evaluate_model(basepath,model):\n",
    "    start = time.time()\n",
    "    correct_detected = 0\n",
    "    total_samples = 0\n",
    "    runtime = 0\n",
    "    for class_id in class_ids:\n",
    "        testpath = os.path.join(basepath,class_id)\n",
    "        class_num = class_ids.index(class_id)\n",
    "        for img in os.listdir(testpath):\n",
    "            try:\n",
    "                total_samples +=1\n",
    "                test_img_array = cv2.imread(os.path.join(testpath, img), cv2.IMREAD_GRAYSCALE)\n",
    "                test_img_array = cv2.resize(test_img_array, (IMG_SIZE, IMG_SIZE))\n",
    "                test_img_array = test_img_array.reshape(-1, IMG_SIZE, IMG_SIZE, 1)\n",
    "                test_img_array = test_img_array/255\n",
    "                score = model.predict(test_img_array)\n",
    "                score = score.argmax(axis=-1)\n",
    "                if score[0] == class_num:\n",
    "                    correct_detected +=1\n",
    "            except Exception as e:\n",
    "                print(\"Test Image path Not Found, Please check your config file: Fow windows dont forget to put path\"\n",
    "                      \"in \\\\\")\n",
    "    runtime = format(time.time() - start)\n",
    "    return runtime, (correct_detected/total_samples)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======================================================\n",
      "             Runtime            : 9.244155645370483  Seconds\n",
      "             Model test accuracy: 96.05 %\n",
      "=======================================================\n",
      "=======================================================\n",
      "             Runtime            : 9.052635192871094  Seconds\n",
      "             Model test accuracy: 96.05 %\n",
      "=======================================================\n"
     ]
    }
   ],
   "source": [
    "test_basepath = \"C:\\\\Users\\\\ghodam2\\\\Desktop\\\\Pruning Technique\\\\test\"\n",
    "run_time,model_pruned_stripped_accuracy = evaluate_model(test_basepath, model_pruned_stripped)\n",
    "\n",
    "                \n",
    "print(\"=======================================================\")\n",
    "print(\"             Runtime            :\", run_time, \" Seconds\")\n",
    "print(\"             Model test accuracy:\", model_pruned_stripped_accuracy ,\"%\")\n",
    "print(\"=======================================================\")\n",
    "\n",
    "run_time,perc_accuracy = evaluate_model(test_basepath, original_model)               \n",
    "print(\"=======================================================\")\n",
    "print(\"             Runtime            :\", run_time, \" Seconds\")\n",
    "print(\"             Model test accuracy:\", perc_accuracy ,\"%\")\n",
    "print(\"=======================================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert the model to tensorflow lite for inferencing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:From c:\\users\\ghodam2\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\lite\\python\\util.py:238: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.convert_variables_to_constants`\n",
      "WARNING:tensorflow:From c:\\users\\ghodam2\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\graph_util_impl.py:270: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.extract_sub_graph`\n",
      "INFO:tensorflow:Froze 14 variables.\n",
      "INFO:tensorflow:Converted 14 variables to const ops.\n",
      "Saved pruned TFLite model to: pruned_tflite_model.tflite\n"
     ]
    }
   ],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model_file(\"C:\\\\Users\\\\ghodam2\\\\Desktop\\\\Pruning Technique\\\\pruned_stripped_model.h5\")\n",
    "pruned_tflite_model = converter.convert()\n",
    "\n",
    "pruned_tflite_file = 'pruned_tflite_model.tflite'\n",
    "\n",
    "with open(pruned_tflite_file, 'wb') as f:\n",
    "  f.write(pruned_tflite_model)\n",
    "\n",
    "print('Saved pruned TFLite model to:', pruned_tflite_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check compressed sizes of each model\n",
    "def get_gzipped_model_size(file):\n",
    "  # Returns size of gzipped model, in bytes.\n",
    "  print(file)\n",
    "  zipped_file = '{}.zip'.format(file)\n",
    "  with zipfile.ZipFile(zipped_file, 'w', compression=zipfile.ZIP_DEFLATED) as f:\n",
    "    f.write(file)\n",
    "\n",
    "  return os.path.getsize(zipped_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TrafficSignalClassifier_v4_2.h5\n",
      "Size of gzipped baseline Keras model: 9123266.00 bytes\n",
      "pruned_stripped_model.h5\n",
      "Size of gzipped pruned Keras model: 985704.00 bytes\n",
      "pruned_tflite_model.tflite\n",
      "Size of gzipped pruned TFlite model: 979980.00 bytes\n"
     ]
    }
   ],
   "source": [
    "orig_model = 'TrafficSignalClassifier_v4_2.h5'\n",
    "prun_model = 'pruned_stripped_model.h5'\n",
    "tflite_model = 'pruned_tflite_model.tflite'\n",
    "\n",
    "print(\"Size of gzipped baseline Keras model: %.2f bytes\" % (get_gzipped_model_size(orig_model)))\n",
    "print(\"Size of gzipped pruned Keras model: %.2f bytes\" % (get_gzipped_model_size(prun_model)))\n",
    "print(\"Size of gzipped pruned TFlite model: %.2f bytes\" % (get_gzipped_model_size(tflite_model)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pruning + Quantisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Froze 14 variables.\n",
      "INFO:tensorflow:Converted 14 variables to const ops.\n"
     ]
    }
   ],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model_file(orig_model)\n",
    "\n",
    "# optimization for size\n",
    "converter.optimizations = [tf.lite.Optimize.OPTIMIZE_FOR_SIZE]\n",
    "\n",
    "# conver the model here in bytes form\n",
    "quantized_and_pruned_tflite_model = converter.convert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantized_and_pruned_tflite_file = 'quantized_and_prune.tflite'\n",
    "\n",
    "with open(quantized_and_pruned_tflite_file, 'wb') as f:\n",
    "  f.write(quantized_and_pruned_tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(interpreter):\n",
    "  input_index = interpreter.get_input_details()[0][\"index\"]\n",
    "  output_index = interpreter.get_output_details()[0][\"index\"]\n",
    "\n",
    "  # Run predictions on ever y image in the \"test\" dataset.\n",
    "  prediction_digits = []\n",
    "  for i, test_image in enumerate(test_images):\n",
    "    if i % 1000 == 0:\n",
    "      print('Evaluated on {n} results so far.'.format(n=i))\n",
    "    # Pre-processing: add batch dimension and convert to float32 to match with\n",
    "    # the model's input data format.\n",
    "    test_image = np.expand_dims(test_image, axis=0).astype(np.float32)\n",
    "    interpreter.set_tensor(input_index, test_image)\n",
    "\n",
    "    # Run inference.\n",
    "    interpreter.invoke()\n",
    "\n",
    "    # Post-processing: remove batch dimension and find the digit with highest\n",
    "    # probability.\n",
    "    output = interpreter.tensor(output_index)\n",
    "    digit = np.argmax(output()[0])\n",
    "    prediction_digits.append(digit)\n",
    "\n",
    "  print('\\n')\n",
    "  # Compare prediction results with ground truth labels to calculate accuracy.\n",
    "  prediction_digits = np.array(prediction_digits)\n",
    "  accuracy = (prediction_digits == test_labels).mean()\n",
    "  return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original model accuracy                  : 0.9645\n",
      "pruned keras without stripped accruacy   : 0.9605\n",
      "pruned keras with stripped accruacy      : 96.05\n",
      "Evaluated on 0 results so far.\n",
      "Evaluated on 1000 results so far.\n",
      "\n",
      "\n",
      "pruned TFLite accuracy                   : 0.9605\n",
      "Evaluated on 0 results so far.\n",
      "Evaluated on 1000 results so far.\n",
      "\n",
      "\n",
      "pruned and quantized TFLite accuracy     : 0.9645\n"
     ]
    }
   ],
   "source": [
    "###################################################################################\n",
    "print('original model accuracy                  :', original_model_accuracy)\n",
    "print('pruned keras without stripped accruacy   :', model_for_pruning_accuracy)\n",
    "print('pruned keras with stripped accruacy      :', model_pruned_stripped_accuracy)\n",
    "\n",
    "###################################################################################\n",
    "interpreter = tf.lite.Interpreter(model_content=pruned_tflite_model)\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "test_accuracy = evaluate_model(interpreter)\n",
    "print('pruned TFLite accuracy                   :', test_accuracy)\n",
    "\n",
    "###################################################################################\n",
    "interpreter = tf.lite.Interpreter(model_content=quantized_and_pruned_tflite_model)\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "test_accuracy = evaluate_model(interpreter)\n",
    "\n",
    "print('pruned and quantized TFLite accuracy     :', test_accuracy)\n",
    "###################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
